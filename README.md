# Facial Emotion Detection
Facial Emotion Detection System

Problem Definition
The context: from recent research, it has been found that as much as 55% of communication of sentiment takes place through facial expressions and other visual cues. Therefore, training a model to identify facial emotions accurately is an important step towards the development of emotionally intelligent behavior in machines with AI capabilities. Automatic facial expression recognition systems could have many applications, including but not limited to any use case that requires human behavior understanding, detection of mental disorders, and creating a higher quality of virtual assistant for customer-facing businesses. Facial emotion detection is an area of computer that is very critical to the advancement of several aspects of social living. It can be used for:

Human-computer interaction: our engagement with AI-enabled devices can be read and provisioned for (our moods can be read and various actions taken, it can be used to save a human in distress or trouble just by reading their countenance and calling the cops e.g. if someone has been held against their will, fear, anxiety can be read and help can be sought, a patient with a medical condition can be monitored for emergency care etc).

CGI-enabled imaging: it can be used to read faces and project that into the screen to appropriately capture facial movements and expressions. Businesses can also leverage this to proactivaly determine engagement with customers.

Forensic investigation: in homicide cases, it can be used to estimate the last few minutes, seconds, even possibly hours of victims involved


The objectives: Create a computer vision model that can accurately detect facial emotions. The model should be able to perform multi-class classification on images of facial expressions, to classify the expressions according to the associated emotion.
The key questions:

How do we reliably source (clean) data and if messy, then perform EDA to make it clean?
How do we carry out research studies into the application of Artificial Emotional Intelligence and advance its cross-discipline interactions nad applications?
How do we achieve an almost perfect performance (precision, recall, F1-Score, etc) that will qialify our work as deployment-ready

The problem formulation:

Reliable and accurate identification of facial emotions.
Gap in human-computer interaction.
About the dataset
The data set consists of 3 folders, i.e., 'test', 'train', and 'validation'. Each of these folders has four subfolders:

‘happy’: Images of people who have happy facial expressions.
‘sad’: Images of people with sad or upset facial expressions.
‘surprise’: Images of people who have shocked or surprised facial expressions.
‘neutral’: Images of people showing no prominent emotion in their facial expression at all.
